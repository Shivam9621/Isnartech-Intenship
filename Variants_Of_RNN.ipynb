{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq6o-9vGKjzn"
      },
      "source": [
        "1. Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXsIyM4kKTbJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.rnn(x)  # h_n: final hidden state\n",
        "        out = self.fc(h_n.squeeze(0))  # Remove extra dimension and pass to linear\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ8-63ToCQ2X",
        "outputId": "5d431f0d-b3c9-49c1-9d3a-87e6a57609f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Input shape: (batch_size, seq_len, input_size)\n",
        "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=1, batch_first=True)\n",
        "x = torch.randn(5, 3, 10)  # (batch, seq_len, input_size)\n",
        "output, hn = rnn(x)\n",
        "print(output.shape)  # (5, 3, 20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32e7fXRoK2dQ"
      },
      "source": [
        "2. LSTM (Long Short-Term Memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2aQH2yAK8P6"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)  # LSTM returns (output, (hidden, cell))\n",
        "        out = self.fc(h_n.squeeze(0))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8nBDA7lCcn4",
        "outputId": "bf30ff72-6feb-480c-e5b0-c6f6e7d09e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=1, batch_first=True)\n",
        "x = torch.randn(5, 3, 10)\n",
        "output, (hn, cn) = lstm(x)\n",
        "print(output.shape)  # (5, 3, 20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZvHE4iELABK"
      },
      "source": [
        "3. GRU (Gated Recurrent Unit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66wCo180LDT0"
      },
      "outputs": [],
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GRU, self).__init__()\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.gru(x)  # GRU also returns output, hidden\n",
        "        out = self.fc(h_n.squeeze(0))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGvTvLR1ChEp",
        "outputId": "eb29164f-d651-4af4-89d0-853c1a7811e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "gru = nn.GRU(input_size=10, hidden_size=20, num_layers=1, batch_first=True)\n",
        "x = torch.randn(5, 3, 10)\n",
        "output, hn = gru(x)\n",
        "print(output.shape)  # (5, 3, 20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0qHUI_LHe8"
      },
      "source": [
        "4. BiLSTM (Bidirectional LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hxEEhGmLM9h"
      },
      "outputs": [],
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        h_cat = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)  # Concatenate forward & backward\n",
        "        out = self.fc(h_cat)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqVi5BQyCoUE",
        "outputId": "cd315857-a5a5-457d-cdf0-35cab3b08223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 40])\n"
          ]
        }
      ],
      "source": [
        "bilstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=1, batch_first=True, bidirectional=True)\n",
        "x = torch.randn(5, 3, 10)\n",
        "output, (hn, cn) = bilstm(x)\n",
        "print(output.shape)  # (5, 3, 40) ‚Üê 20 forward + 20 backward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ghMZ6QLYXF",
        "outputId": "98179528-d394-46b6-9ee0-e1deab490039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 2\n",
        "seq_len = 5\n",
        "input_dim = 300  # e.g., GloVe vector size\n",
        "\n",
        "# Random input tensor simulating embedded word vectors\n",
        "x = torch.randn(batch_size, seq_len, input_dim)\n",
        "\n",
        "# Instantiate and test the model\n",
        "model = BiLSTM(input_dim=300, hidden_dim=128, output_dim=2)\n",
        "output = model(x)\n",
        "print(output.shape)  # Should be [2, 2] for 2-class classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETrTk4xQ4Jbu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Dummy sequence: [batch_size, seq_len, input_dim]\n",
        "x = torch.randn(1, 5, 10)  # Batch of 1, sequence of 5 words, each word = 10-dim vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9RVYA4HY4PoK"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(10, 8, batch_first=True)\n",
        "        self.fc = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.rnn(x)\n",
        "        return torch.sigmoid(self.fc(h_n.squeeze(0)))\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(10, 8, batch_first=True)\n",
        "        self.fc = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        return torch.sigmoid(self.fc(h_n.squeeze(0)))\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(10, 8, batch_first=True)\n",
        "        self.fc = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.gru(x)\n",
        "        return torch.sigmoid(self.fc(h_n.squeeze(0)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpckH2uG1XRY",
        "outputId": "de2eefc3-e0be-4a77-833f-30f546ffcb60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simple RNN Output: 0.5955777764320374\n",
            "LSTM Output: 0.5452982187271118\n",
            "GRU Output: 0.5709724426269531\n"
          ]
        }
      ],
      "source": [
        "# Initialize models\n",
        "rnn_model = SimpleRNN()\n",
        "lstm_model = LSTM()\n",
        "gru_model = GRU()\n",
        "\n",
        "# Forward pass with same input\n",
        "out_rnn = rnn_model(x)\n",
        "out_lstm = lstm_model(x)\n",
        "out_gru = gru_model(x)\n",
        "\n",
        "print(\"Simple RNN Output:\", out_rnn.item())\n",
        "print(\"LSTM Output:\", out_lstm.item())\n",
        "print(\"GRU Output:\", out_gru.item())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}